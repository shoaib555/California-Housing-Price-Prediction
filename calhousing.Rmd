## california housing prediction 

```{r}
#load data
hs=read.csv("hous.csv")
dim(hs)
str(hs)
summary(hs[,-c(1,2)])
```
## EDA
```{r}
library(png)
library(ggplot2)
library(grid)
library(dplyr)
cal=png::readPNG("map.png")
hs%>%ggplot(aes(longitude,latitude,col=median_house_value))+
  annotation_custom(rasterGrob(cal,width = unit(1,"npc"),height = unit(1,"npc")),-Inf, Inf, -Inf, Inf) +
  geom_point() + scale_color_gradientn(colours = c("blue","green","red"))

#creating three levels of median_house_value based on above plot
hs$value=ifelse(hs$median_house_value<=100000,"below 100k",ifelse(hs$median_house_value >100000 & hs$median_house_value <=250000,"btw 100k and 250k","above 250k"))
hs$value=as.factor(hs$value)

#collapsing the factors of ocean proximity into 4
hs$ocean_proximity[hs$ocean_proximity=="ISLAND"]="NEAR BAY"
```

## outlier treatment
```{r}
#replacing the outliers with NA
out=boxplot(hs$total_rooms)$out
hs[hs$total_rooms %in% out,"total_rooms"] = NA
summary(hs)

out=boxplot(hs$total_bedrooms)$out
hs[hs$total_bedrooms %in% out,"total_bedrooms"] = NA
summary(hs)

out=boxplot(hs$population)$out
hs[hs$population %in% out,"population"] = NA
summary(hs)

out=boxplot(hs$households)$out
hs[hs$households %in% out,"households"] = NA
summary(hs)

out=boxplot(hs$median_income)$out
hs[hs$median_income %in% out,"median_income"] = NA
summary(hs)

hs=hs[,-c(1,2)]
summary(hs)

#using pmm to replace outliers
library(mice)
md.pattern(hs)
mymice=mice(hs,m=5,method="pmm")
mymiceComplete=complete(mymice,2)
summary(mymiceComplete)
hs=mymiceComplete
summary(hs)

hs1=hs[,-c(8,9)]

#histogram after outliers treatment
par(mfrow=c(2,4))
for (i in names(hs1)){
  hist(hs1[[i]],col=c("blue"),main = names(hs1[i]))
}
#boxplots after outlier treatment
for (i in names(hs1)){
  boxplot(hs1[[i]],col=c("blue"),main = names(hs1[i]))
}
par(mfrow=c(1,1))
```

## creating new features
```{r}
hs$ratio_of_bedrooms=hs$total_bedrooms/hs$total_rooms
hs$household_per_population=hs$households/hs$population
hs$rooms_per_household=hs$total_rooms/hs$households

str(hs)
```

## checking for correlation
```{r}
library(corrplot)
corrplot(cor(hs[,-c(8,9)]),type="upper",method="number")
```

## Drooping variable that are less correlated with the target variable and creating dummy variables
```{r}
hs=hs[,-c(3:5)]
#creating dummy variable for location and area type
library(caret)
dd=dummyVars(" ~ ocean_proximity", data = hs,fullRank = F)
d1=data.frame(predict(dd, newdata = hs))
hs=cbind(hs,d1)

dd=dummyVars(" ~ value", data = hs,fullRank = F)
d1=data.frame(predict(dd, newdata = hs))
hs=cbind(hs,d1)

hs=hs[,-c(5,6,12)]

str(hs)

```

## Linear Regression
```{r}
#splitting data into test and train 70:30
library(caTools)
set.seed(500)
spl=sample.split(hs,SplitRatio = 0.7)
tr=subset(hs,spl==T)
ts=subset(hs,spl==F)

set.seed(152)
lm=lm(median_house_value~.,data=tr)
summary(lm)

step(lm,direction = "both")

set.seed(31)
lm=lm(median_house_value ~ housing_median_age + total_rooms + 
    median_income + ratio_of_bedrooms + household_per_population + 
    rooms_per_household + ocean_proximity.INLAND + ocean_proximity.NEAR.BAY + 
    value.above.250k + value.below.100k, data = tr)

summary(lm)

plot(lm)

#using cook distance to drop influential rows
cd=cooks.distance(lm)
i=which(cd>4*mean(cd))
length(i)
tr1=tr[-i,]

set.seed(43)
lm=lm(median_house_value~.,data=tr1)
summary(lm)

#box cox transformation to treat hetroscedasticity
library(lmtest)
bptest(lm)

bc=MASS::boxcox(lm)
best_lam=bc$x[which(bc$y==max(bc$y))]
best_lam

set.seed(211)
lm=lm((median_house_value)^0.141~.,data=tr1)
summary(lm)

#predicting on the test
ts$pred=predict(lm,newdata=ts)
library(MLmetrics)
RMSE(ts$median_house_value,ts$pred)


#Compute R^2 from true and predicted values
rsq <- function (x, y) cor(x, y) ^ 2
rsquare=rsq(ts$median_house_value,ts$pred)
rsquare
```

## Ridge
```{r}
library(caret)
set.seed(200)
r1=train(median_house_value~.,method="glmnet",data=tr,trControl=trainControl(method="repeatedcv",number=10,repeats=5,verboseIter = T),tuneGrid=expand.grid(alpha=0,lambda=seq(-10,10,length=20)))
summary(r1)
plot(r1)
ts$pred=predict(r1,ts,type="raw")
RMSE(ts$pred,ts$median_house_value)
#Compute R^2 from true and predicted values
rsq <- function (x, y) cor(x, y) ^ 2
rsquare=rsq(ts$median_house_value,ts$pred)
rsquare
```

## Lasso
```{r}
set.seed(258)
la=train(median_house_value~.,method="glmnet",data=tr,trControl=trainControl(method="repeatedcv",number=10,repeats=5,verboseIter = T),tuneGrid=expand.grid(alpha=1,lambda=seq(-10,250,length=10)))
plot(la)
ts$pred=predict(la,ts,type="raw")
RMSE(ts$pred,ts$median_house_value)
#Compute R^2 from true and predicted values
rsq <- function (x, y) cor(x, y) ^ 2
rsquare=rsq(ts$median_house_value,ts$pred)
rsquare
```

## DT
```{r}
library(rpart)
library(rpart.plot)
library(rattle)
set.seed(897)
r.ctrl=rpart.control(minisplit=10,minbucket=5,cp=0,xval=10)
dt=rpart(formula=tr$median_house_value~.,data=tr,control = r.ctrl)
plotcp(dt)
dt$cptable
r.ctrl=rpart.control(minisplit=30,minbucket=5,cp=0.00031,xval=10)
dt1=rpart(formula=tr$median_house_value~.,data=tr,control = r.ctrl)
ts$pred=predict(dt1,ts,type="vector")
RMSE(ts$pred,ts$median_house_value)
#Compute R^2 from true and predicted values
rsq <- function (x, y) cor(x, y) ^ 2
rsquare=rsq(ts$median_house_value,ts$pred)
rsquare
```

## Random Forest
```{r}
library(randomForest)
#set seed again for randomness
set.seed(1000)
#build first RF model
rf=randomForest(median_house_value~.,data=tr,ntree=200,mtry=3,nodesize=30,importance=T)
print(rf)
plot(rf)

#tune rf to identify the best mtry
set.seed(1000)
trrf=tuneRF(tr[,-c(4)],y=tr$median_house_value,mtryStart = 2,stepFactor = 1.5,ntree=100,improve = 0.0001,nodesize=10,
            trace=T,plot=T,doBest = T,importance=T)
print(trrf)
plot(trrf)

rf=randomForest(median_house_value~.,data=tr,ntree=100,mtry=4,nodesize=10,importance=T)
print(rf)
plot(rf)

ts$pred=predict(rf,ts,type="response")
RMSE(ts$pred,ts$median_house_value)
#Compute R^2 from true and predicted values
rsq <- function (x, y) cor(x, y) ^ 2
rsquare=rsq(ts$median_house_value,ts$pred)
rsquare
```

## Xgboost
```{r}
library(xgboost)
library(caTools)
set.seed(502)
spl=sample.split(hs,SplitRatio = 0.7)
tr=subset(hs,spl==T)
ts=subset(hs,spl==F)
set.seed(1243)
gd_features_train<-as.matrix(tr[,-4])
gd_label_train<-as.matrix(tr[,4])
gd_features_test<-as.matrix(ts[,-4])
xgb.fit <- xgboost(
  data = gd_features_train,
  label = gd_label_train,
  eta = 0.09,
  max_depth =7,
  min_child_weight = 10,
  nrounds = 50,
  nfold = 10,
  objective = "reg:linear", 
  verbose = 0,               
  early_stopping_rounds = 10,
  
)
ts$pred=predict(xgb.fit, gd_features_test)
RMSE(ts$pred,ts$median_house_value)
#Compute R^2 from true and predicted values
rsq <- function (x, y) cor(x, y) ^ 2
rsquare=rsq(ts$median_house_value,ts$pred)
rsquare
```

## Gbm
```{r}
set.seed(1271)
library(gbm)
set.seed(501)
gbb <- gbm(
  formula = median_house_value~.,
  distribution = "gaussian",
  data = tr,
  n.trees = 500,
  interaction.depth = 3,
  shrinkage = 0.1,
  cv.folds = 10,
)  
#fiiting on train
ts$pred=predict(gbb,ts,type="response")

RMSE(ts$pred,ts$median_house_value)
#Compute R^2 from true and predicted values
rsq <- function (x, y) cor(x, y) ^ 2
rsquare=rsq(ts$median_house_value,ts$pred)
rsquare
```

